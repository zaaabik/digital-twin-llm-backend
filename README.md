# Digital twin LLM backend

Simplest way to run this container do it on Kaggle.com

Chose notebook with 2xT4 gpu and then run notebook [kaggle_serving/llm-serve.ipynb](kaggle_serving/llm-serve.ipynb).
